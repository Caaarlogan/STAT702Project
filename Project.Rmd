---
title: "Project"
author: "Carlo Carbonilla"
date: "13/05/2021"
output:
  html_document:
    df_print: paged
---

Load the required Packages.

```{r}
#Loading the Packages
library(dplyr)
library(tidyverse)
library(lubridate)
```

Question 1. 

Solution 1.a) 

Import the data from STAT702_project_sales_data.csv file.

```{r}
sales <- read.csv(file = 'STAT702_project_sales_data.csv')
head(sales)
```

To format week as a date, first step is to Convert week column from character to date type.
And then, use the lubridate function to extract the month.

```{r}
sales$week <- as.Date(sales$week, format =  "%d/%m/%y")
head(sales)
```

Given the project requirements, Filtering dataframe to dates in 2012 and with the product sku of 216419 (assigned to group #2)

```{r}
productSales <- sales %>% filter(sku_id == 216419)
productSales
```

Here the variables Month and Year witholds the total number of units sold by month and year respectively,

```{r}
Month <- month(productSales$week)
Year <- year(productSales$week)

monthlySales <- aggregate(cbind(units_sold)~Month+Year,
             data=productSales,FUN=sum)

monthlySales$MonthYear <- as.Date(paste(1,monthlySales$Month,monthlySales$Year,sep="/"), format="%d/%m/%Y")

monthlySales
```

There are 31 rows resides in the table where each row represents a month starting from January 2011 all the way till July 2013 (31 Months).
Furtherfore, this table has laid the foundation to help plotting the data on a graph to observe any trends/patterns. 

```{r}
ggplot(monthlySales, aes(MonthYear, units_sold, group=1)) + 
  geom_line() +
  geom_point() +
  scale_x_date(date_breaks = "1 month", date_labels = "%m-%Y") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ggtitle("Monthly Sales") +
  xlab("Month and Year") +
  ylab("Units Sold")
```


This plot shows that the montly sales over a period of time for the Product ID- 216419 which has been fluctuating with in \$15000 and \$25000. However, the sales went unreasonably over $35000 in January 2012 which could be either because of New year's holiday weekend or some other unknown factors. It's best to remove the July 2013 sales out of the analysis it only contains 7 days sales total. 
To sum it up, this plot describes the increase and decrease in product sale each month



##Solution 1.b) 

First of all, we need to sum the total units sold by each store, so that further analysis can be drawn.

```{r}
StoreID <- productSales$store_id

storeSales <- aggregate(cbind(units_sold)~StoreID,
             data=productSales,FUN=sum)

storeSales$StoreID <- as.character(storeSales$StoreID)

storeSales
```

Store Id with respect to units sold by that store. Store with ID:8023 has max number of sales which is close to 29000 units followed by store ID 9613.
In order to draw comparison, let's make a plot using geom_bar and see the sales trend between the various stores. However, there are some stores where the sale numbers are relatively low. For instance, store id: 9001 sold the least number of units (1095 only). Therefore, apprximately 9000 is the average unit sold ratio among all the store. 

```{r}
ggplot(data=storeSales, aes(x=reorder(StoreID, -units_sold), y=units_sold)) +
  geom_bar(stat="identity", fill="steelblue") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(title = "Total Units Sold of Stores", y = "Units Sold", x = "Store ID")
```

Summary of sales of all the store collectively. Looking at the graph above we get an idea of what a good performing store looks like and on the right hand side of the graph are the stores that are not performing so well. 

```{r}
summary(storeSales)
```

Given there are 67 stores in total with the sales mean of ~9000 units per store. Therefore, the stores that had sold more that 9000 units can be considered as good performing store. On the other hand, stores that sold below 9000 units can be categorized as the less/poor performing stores.
To drill this down further, making a new variable called top10Sales which withholds the top 10 performing stores based of the number of units sold.

```{r}
top10Sales <- head(storeSales %>% arrange(desc(units_sold)),10)
top10Sales
```

All of those 10 store are well above the mean calculated earlier.

Graph of Top 10 Stores

```{r}
ggplot(data=top10Sales, aes(x=reorder(StoreID, -units_sold), y=units_sold)) +
  geom_bar(stat="identity", fill="steelblue") +
  geom_text(aes(label=units_sold), vjust=1.6, color="white", size=3.5) +
  labs(title = "Top 10 Stores in Units Sold", y = "Units Sold", x = "Store ID")
```
```{r}
summary(top10Sales)
```

Hence, this is the data that will be presented to the General Manager Sales.

Similarly, bottom10Sales variable withholds the sales record of the 10 least performing stores. 

```{r}
bottom10Sales <- head(storeSales %>% arrange(units_sold),10)
bottom10Sales
```

Graph of Bottom 10 Stores.

```{r}
ggplot(data=bottom10Sales, aes(x= reorder(StoreID, units_sold), y=units_sold)) +
  geom_bar(stat="identity", fill="steelblue") +
  geom_text(aes(label=units_sold), vjust=1.6, color="white", size=3.5) +
  labs(title = "Bottom 10 Stores in Units Sold", y = "Units Sold", x = "Store ID")
```
```{r}
summary(bottom10Sales)
```

All of the store above are well below the mean calculated earlier. Therefore, this step by step approach is useful to understand the sale trends between the stores and how well/poor are they performing. There are store with high selling numbers which could be based on the customer base, location of the store of the selling techniques used by employees (Sales driven culture) where as there are store with less selling numbers which again could depend upon the various factors. 
However, the data and the visuals created above put a baseline for the Management to create strategies on how the sale can be lifted and what are the stores that requires  more attention.



Question 2.

(a)

i.

Filter dataframe to dates in 2012 and with the product sku of 216233
```{r}
productSales2012 <- sales %>% filter(week >= as.Date("2012-01-01"), week <= as.Date("2012-12-31"), sku_id == 216233)
head(productSales2012)
```

k = setup cost
A = number of items demanded per annum
c = purchase cost per item
h = holding cost per item per annum
Q* = optimum order quantity (number of items)
T = time between order = length of the inventory cycle = Q/A

Find total units sold for 2012
```{r}
A <- sum(productSales2012$units_sold) # Annual demand
A
```

Find economic order quantity
```{r}
k <- 130 # ordering cost
h <- 1.5 # holding cost
Q <- sqrt((2*k*A) / h) # optimum order quantity 
round(Q,0)
```

Find time between order
```{r}
T <- 365 * sqrt(2*k/(A*h)) # inventory cycle 
round(T,0)
```

Find annual inventory cost
```{r}
inv_cost_ann <- k*(A/Q) + h*(Q/2) # annual inventory cost
inv_cost_ann
```

During 2012, 169591 units of this product was sold and is assumed to be A, the number of items demanded per annum. Based on the 2012 sales, the company should order 5422 units of the product every 12 days. The annual inventory cost is $8132.68


ii.

Find total price per unit
```{r}
p = 0.05 * (inv_cost_ann/A)
p
```

```{r}

```


Question 3.

Load the data

```{r}
review <- read.csv(file = 'STAT702_project_reviews_data.csv')
head(review)
```

Filter the product given to our group

```{r}
selectedProduct <- review %>% filter(asin == "B00005249G")
selectedProduct
```

```{r}
summary(selectedProduct)
```


```{r}
ggplot(selectedProduct, aes(overall)) + 
  geom_bar() 
```


Explanation:



3b)

Start here:


```{r}
data <- selectedProduct %>%
mutate(linenumber = row_number());
head(data)
```


